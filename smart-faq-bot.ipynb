# -----------------------------------------------------------
# üß© Smart FAQ/Support Bot ‚Äì Multi‚Äëtenant with User Login, Upload & Feedback
# -----------------------------------------------------------
# Each user has credentials ‚Üí their own vector store (RAG) ‚Üí isolated answers.
# Admin can create users in the Management portal.
# Supported file types: PDF, CSV, DOCX, TXT, MD.
# -----------------------------------------------------------

# CELL 1 ‚Äì¬†Install deps (run once)
!pip install -q langchain-core langchain-community langchain-chroma langchain-ollama \
  sentence-transformers chromadb gradio pymupdf "unstructured[docx]" tqdm

# CELL 2 ‚Äì Start Ollama & pull models
import subprocess, threading, time, requests, json, hashlib, shutil, tempfile, os, uuid
from pathlib import Path

LLM_MODEL = "mistral:7b"
EMBED_MODEL = "nomic-embed-text"

# Launch Ollama server in the background (if not running)
threading.Thread(target=lambda: subprocess.run(["ollama", "serve"]), daemon=True).start()
for _ in range(30):
    try:
        if requests.get("http://localhost:11434").ok:
            break
    except Exception:
        time.sleep(1)
else:
    raise RuntimeError("‚ùå Ollama not reachable. Is it installed?")

!ollama pull {LLM_MODEL}
!ollama pull {EMBED_MODEL}

# CELL 3 ‚Äì¬†Imports & configuration
import gradio as gr
from typing import List
from langchain_community.document_loaders import (
    PyPDFLoader, CSVLoader, TextLoader,
    UnstructuredMarkdownLoader, UnstructuredWordDocumentLoader,
)
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_chroma import Chroma
from langchain_community.llms import Ollama
from langchain_ollama.embeddings import OllamaEmbeddings
from langchain.prompts import PromptTemplate
from langchain.chains import RetrievalQA

# ---- Globals ----
TMP_ROOT = Path(tempfile.mkdtemp(prefix="faq_multi_"))
USERS_JSON = TMP_ROOT / "users.json"
USERS_JSON.write_text(json.dumps({"admin": hashlib.sha256("admin".encode()).hexdigest()}))  # default admin/admin

SPLITTER = RecursiveCharacterTextSplitter(chunk_size=512, chunk_overlap=64)
EMBEDDER = OllamaEmbeddings(model=EMBED_MODEL)

PROMPT = PromptTemplate(
    input_variables=["context", "question"],
    template=(
        "Answer ONLY from the context below. "
        "If unsure, say: 'I don't know based on the provided documents.'\n\n"
        "Context:\n{context}\n\n"
        "Question: {question}\nAnswer:"
    ),
)

# ---- Helper functions ----

def hash_pw(pw: str) -> str:
    """Return SHA‚Äë256 hex digest for the given password."""
    return hashlib.sha256(pw.encode()).hexdigest()


def load_users():
    return json.loads(USERS_JSON.read_text())


def save_users(users):
    USERS_JSON.write_text(json.dumps(users))


def register_user(username: str, password: str):
    users = load_users()
    if username in users:
        return False, "User already exists"
    users[username] = hash_pw(password)
    save_users(users)
    (TMP_ROOT / f"user_{username}").mkdir(exist_ok=True)
    return True, "‚úÖ User created"


def authenticate(username: str, password: str):
    users = load_users()
    return users.get(username) == hash_pw(password)


# ---- Document helpers ----

def read_files_local(paths: List[Path]):
    docs = []
    for p in paths:
        try:
            if p.suffix.lower() == ".pdf":
                loader = PyPDFLoader(str(p))
            elif p.suffix.lower() == ".csv":
                loader = CSVLoader(str(p))
            elif p.suffix.lower() == ".txt":
                loader = TextLoader(str(p), encoding="utf-8")
            elif p.suffix.lower() == ".md":
                loader = UnstructuredMarkdownLoader(str(p))
            elif p.suffix.lower() in {".doc", ".docx"}:
                loader = UnstructuredWordDocumentLoader(str(p))
            else:
                print(f"[!] Unsupported: {p.name}")
                continue
            for d in loader.load():
                d.metadata["source"] = p.name
                docs.append(d)
        except Exception as e:
            print(f"[!] Failed on {p.name}: {e}")
    return docs


def build_chain_for_user(username: str):
    """Return (vector_store, retrieval_chain) for the specified user."""
    user_dir = TMP_ROOT / f"user_{username}"
    user_dir.mkdir(exist_ok=True)

    if (user_dir / "chroma.sqlite").exists():
        vector = Chroma(persist_directory=str(user_dir), embedding_function=EMBEDDER)
    else:
        vector = Chroma(collection_name=f"{username}_coll", embedding_function=EMBEDDER, persist_directory=str(user_dir))

    llm = Ollama(model=LLM_MODEL)
    chain = RetrievalQA.from_chain_type(
        llm=llm,
        retriever=vector.as_retriever(search_type="mmr", search_kwargs={"k": 4}),
        return_source_documents=True,
        chain_type_kwargs={"prompt": PROMPT},
    )
    return vector, chain


# ---- Gradio State Keys ----
# state = {"user": str|None, "vector": VectorStore, "chain": RetrievalQA, "history": list}

# CELL 4 ‚Äì¬†Gradio UI definitions
with gr.Blocks(title="Smart FAQ/Support Bot ‚Äì Multi‚Äëtenant") as demo:
    gr.Markdown("## üß© Smart FAQ/Support Bot (Multi‚Äëtenant) ‚Äì¬†Login, Upload, Ask")

    session_state = gr.State({"user": None, "vector": None, "chain": None, "history": []})

    # ----- Admin Tab -----
    with gr.Tab("üîë Admin ‚Äì¬†User Mgmt"):
        gr.Markdown("Login as **admin** to create users. Default creds: admin/admin")
        admin_user = gr.Textbox(label="Admin username", value="admin")
        admin_pw = gr.Textbox(label="Admin password", type="password", value="admin")
        new_user = gr.Textbox(label="New username")
        new_pw = gr.Textbox(label="New password", type="password")
        create_btn = gr.Button("Create User", variant="primary")
        admin_status = gr.Markdown()

        def create_user_fn(auser, apw, nuser, npw):
            if not authenticate(auser, apw) or auser != "admin":
                return "‚ùå Invalid admin credentials"
            ok, msg = register_user(nuser.strip(), npw.strip())
            return msg

        create_btn.click(create_user_fn, inputs=[admin_user, admin_pw, new_user, new_pw], outputs=admin_status)

    # ----- Login & Upload Tab -----
    with gr.Tab("üîê Login & Upload"):
        login_user = gr.Textbox(label="Username")
        login_pw = gr.Textbox(label="Password", type="password")
        login_btn = gr.Button("Login", variant="primary")
        login_status = gr.Markdown()

        upload_files = gr.Files(label="Upload docs (pdf, csv, docx, txt, md)", file_count="multiple")
        index_btn = gr.Button("Index Documents", variant="primary")
        upload_status = gr.Markdown()

        def login_fn(state, u, p):
            if authenticate(u, p):
                vector, chain = build_chain_for_user(u)
                state.update({"user": u, "vector": vector, "chain": chain, "history": []})
                return state, f"‚úÖ Logged in as {u}"
            return state, "‚ùå Invalid credentials"

        def ingest_fn(state, files):
            if not state.get("user"):
                return state, "‚ö†Ô∏è Login first"
            if not files:
                return state, "‚ö†Ô∏è Upload at least one file"
            user_dir = TMP_ROOT / f"user_{state['user']}"
            local_paths = []
            for f in files:
                tgt = user_dir / Path(f.name).name
                shutil.copy(f.name, tgt)
                local_paths.append(tgt)
            docs = read_files_local(local_paths)
            if not docs:
                return state, "‚ö†Ô∏è No supported docs"
            chunks = SPLITTER.split_documents(docs)
            state["vector"].add_documents(chunks)
            if hasattr(state["vector"], "persist"):
                try:
                    state["vector"].persist()
                except Exception as e:
                    print("[persist warning]", e)
            return state, f"‚úÖ Indexed {len(docs)} docs"

        login_btn.click(login_fn, inputs=[session_state, login_user, login_pw], outputs=[session_state, login_status])
        index_btn.click(ingest_fn, inputs=[session_state, upload_files], outputs=[session_state, upload_status])

    # ----- Chat Tab -----
    with gr.Tab("üí¨ Chatbot"):
        chatbot = gr.Chatbot(height=400, type="messages")
        q_box = gr.Textbox(placeholder="Ask...", label="Your question")
        send_btn = gr.Button("Send", variant="primary")
        clear_btn = gr.Button("Clear chat")

        def chat_fn(state, query):
            if not state.get("user") or not state.get("chain"):
                return state, []
            query = (query or "").strip()
            if not query:
                return state, state.get("history", [])
            try:
                res = state["chain"].invoke({"query": query})
                answer = res["result"]
            except Exception as e:
                answer = f"‚ö†Ô∏è {type(e).__name__}: {e}"
            hist = state.setdefault("history", [])
            hist.append({"role": "user", "content": query})
            hist.append({"role": "assistant", "content": answer})
            return state, hist

        def clear_fn(state):
            state["history"] = []
            return state, []

        send_btn.click(chat_fn, inputs=[session_state, q_box], outputs=[session_state, chatbot])
        clear_btn.click(clear_fn, inputs=session_state, outputs=[session_state, chatbot])
